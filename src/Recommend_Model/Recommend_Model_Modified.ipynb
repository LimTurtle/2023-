{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3623a464",
   "metadata": {},
   "source": [
    "## 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf46884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "with open('../Datasets/train.json', 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e6ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(json_data)\n",
    "train_data = train_data.drop(['id', 'plylst_title', 'updt_date'], axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61bcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Datasets/song_meta_with_likes.json', 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d00a9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data = pd.DataFrame(json_data)\n",
    "song_data = song_data.drop(['album_name', 'song_gn_gnr_basket'], axis=1)\n",
    "song_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf2ecba",
   "metadata": {},
   "source": [
    "## 데이터 열 이름 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cf5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.rename(columns={'songs':'song_id'}, inplace=True)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2dcc1c1",
   "metadata": {},
   "source": [
    "## 데이터 추출\n",
    "\n",
    "- 500개의 플레이리스트 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec8482",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample = train_data[500:1000].copy()\n",
    "train_data_sample = train_data_sample.reset_index(drop=True)\n",
    "#train_data_sample = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c5ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data.rename(columns={'id':'song_id', 'song_gn_dtl_gnr_basket': 'gnr'}, inplace=True)\n",
    "song_data = song_data.astype({'issue_date':'int64'})\n",
    "song_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6f0145",
   "metadata": {},
   "source": [
    "## 노래별 가중치 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 좋아요 개수 분포 확인을 위한 코드\n",
    "clean_song_data = song_data[song_data['like_cnt_song'] > 0]\n",
    "clean_song_data['like_cnt_song'].hist(bins=100)\n",
    "clean_song_data['like_cnt_song'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1, 0.001, 0.3, 1.5, 9, 3600]  # 구간 분할\n",
    "labels = [0, 0.8, 0.85, 0.9, 0.95]  # 구간별 가중치 지정\n",
    "\n",
    "song_data['weight'] = pd.cut(song_data['like_cnt_song'], bins=bins, labels=labels)  # 구간별 가중치 지정\n",
    "song_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdd9aa0",
   "metadata": {},
   "source": [
    "# 한국어 -> 영어 변환\n",
    "- 한국어 전처리에 어려움이 있어서, 영어로 모두 변환 후 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9987dda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from googletrans import Translator\n",
    "import time\n",
    "\n",
    "def trans_to_eng(tags):\n",
    "    time.sleep(1)\n",
    "    translator = Translator()\n",
    "    translated = translator.translate(tags, src = 'ko', dest = 'en')\n",
    "    return translated.text\n",
    "\n",
    "for i in range(len(train_data_sample)):\n",
    "    eng_tags = [trans_to_eng(tag) for tag in train_data_sample['tags'][i]]\n",
    "    train_data_sample['tags'][i] = eng_tags\n",
    "\n",
    "train_data_sample.to_json('../Datasets/train_eng1.json', orient='records')\n",
    "train_data_sample.head(30)\n",
    "\n",
    "    \n",
    "#train_data.head()\n",
    "#eng_tags = [trans_to_eng(tag) for tag in train_data['tags'][1]]\n",
    "#print(\"Kor: \", train_data['tags'][1])\n",
    "#print(\"Eng: \", eng_tags)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('../Datasets/train_eng.json', 'r', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c58672",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_data_eng = pd.DataFrame(json_data)\n",
    "train_data_eng.head(10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4c7c3",
   "metadata": {},
   "source": [
    "# 태그 자연어 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c3fba",
   "metadata": {},
   "source": [
    "### 특수문자 및 공백 제외 + 대->소문자 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c35cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import re\n",
    "\n",
    "print(train_data_eng['tags'][3])\n",
    "pattern = re.compile('[^a-zA-Z0-9]')#특수문자나 공백을 띄어쓰기로 처리할지는 이후 테스트\n",
    "idx = 0\n",
    "for tags in train_data_eng['tags']:\n",
    "    eng_tags = []\n",
    "    for tag in tags:\n",
    "        temp_tags = re.sub(pattern, ' ', tag).lower().split()\n",
    "        for temp_tag in temp_tags:\n",
    "            eng_tags.append(temp_tag)\n",
    "    train_data_eng['tags'][idx] = eng_tags\n",
    "    idx += 1\n",
    "print(train_data_eng['tags'][3])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78efbc",
   "metadata": {},
   "source": [
    "### Stopwords 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('popular') # nltk 라이브러리 사용을 위해 다운해야 함\n",
    "\n",
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(train_data_eng)):\n",
    "    eng_tags = [tag for tag in train_data_eng['tags'][i] if not tag in stops]\n",
    "    if train_data_eng['tags'][i] != eng_tags:\n",
    "        print(train_data_eng['tags'][i])\n",
    "        print(eng_tags)\n",
    "    train_data_eng['tags'][i] = eng_tags\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcb4758",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "stemmer = nltk.stem.SnowballStemmer('english')\n",
    "for i in range(len(train_data_eng)):\n",
    "    eng_tags = [stemmer.stem(tag) for tag in train_data_eng['tags'][i]]\n",
    "    train_data_eng['tags'][i] = eng_tags\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f2db71",
   "metadata": {},
   "source": [
    "### 중복 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a8e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(train_data_eng)):\n",
    "    eng_tags = list(dict.fromkeys(train_data_eng['tags'][i]))\n",
    "    train_data_eng['tags'][i] = eng_tags\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d08b13",
   "metadata": {},
   "source": [
    "### 한 글자로 된 단어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51883c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(train_data_eng)):\n",
    "    eng_tags = [tag for tag in train_data_eng['tags'][i] if len(tag) > 1]\n",
    "    train_data_eng['tags'][i] = eng_tags\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ea2ce",
   "metadata": {},
   "source": [
    "### 추가적인 자연어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770dddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# '록' 또는 '락' 이 'lock' 으로 번역되는 문제가 있어서, 'rock' 으로 일괄적으로 수정\n",
    "pattern = re.compile(r'\\block\\b')\n",
    "for i in range(len(train_data_eng)):\n",
    "    eng_tags = [re.sub(pattern, 'rock', tag) for tag in train_data_eng['tags'][i]]\n",
    "    train_data_eng['tags'][i] = eng_tags\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a3f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_data_sample = train_data_eng.copy()\n",
    "train_data_sample = train_data_sample.reset_index(drop=True)\n",
    "train_data_sample.head(20)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8079fb88",
   "metadata": {},
   "source": [
    "## 태그 병합\n",
    "\n",
    "- 같은 노래에 부여된 서로 다른 태그들을 합친다\n",
    "- 그 결과 동일한 태그 리스트가 거의 모든 노래에 부여되었다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790f2755",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample = train_data_sample.explode('song_id', ignore_index=True)\n",
    "train_data_sample.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6056ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = dict()\n",
    "\n",
    "for i in range(len(train_data_sample)):\n",
    "    song = train_data_sample['song_id'][i]\n",
    "    tag = train_data_sample['tags'][i]\n",
    "    \n",
    "    if song in train_dict:\n",
    "        for j in tag:\n",
    "            train_dict[song].add(j)\n",
    "    \n",
    "    else:\n",
    "        train_dict[song] = set(tag)\n",
    "        \n",
    "print(train_dict[157435])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a038475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample.drop_duplicates(subset='song_id', keep='first',inplace=True)\n",
    "train_data_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_data_sample)):\n",
    "    song = train_data_sample['song_id'].iloc[i]\n",
    "    \n",
    "    train_data_sample['tags'].iloc[i] = list(train_dict[song])\n",
    "\n",
    "train_data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd80db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_tag_appended = pd.merge(train_data_sample, song_data)\n",
    "song_tag_appended = song_tag_appended.astype({'song_id':'int64'})\n",
    "song_tag_appended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_tag_appended.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c740d7b",
   "metadata": {},
   "source": [
    "## Word2Vec 사용\n",
    "\n",
    "- 태그 리스트들을 word2vec로 학습시켜 태그 하나와 연관된 다른 태그들을 유추"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc470359",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sample2 = train_data[500:1000].copy()\n",
    "#train_data_sample2 = train_data_eng.copy()\n",
    "train_data_sample2 = train_data_sample2.reset_index(drop=True)\n",
    "#train_data_sample2 = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab58103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "w2v = Word2Vec(sentences = song_tag_appended['tags'], vector_size = 100, \n",
    "               window = 5, min_count = 15, workers = 4, sg = 1)\n",
    "\n",
    "w2v.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4962276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(w2v.wv.most_similar('rock'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ab2ee5",
   "metadata": {},
   "source": [
    "# 태그 불균형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d9647",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_song_num_dict(data):\n",
    "    song_ids = dict()\n",
    "    song_num = dict()\n",
    "    max_num = 0\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        songs = data['song_id'][i]\n",
    "        tags = data['tags'][i]\n",
    "        \n",
    "        for j in tags:\n",
    "            if not j in song_ids:\n",
    "                song_ids[j] = set(songs)\n",
    "            \n",
    "            else:\n",
    "                song_ids[j].update(songs)\n",
    "    \n",
    "    for i in song_ids:\n",
    "        song_num[i] = len(song_ids[i])\n",
    "        \n",
    "        max_num = max(song_num[i], max_num)\n",
    "    \n",
    "    return song_num, max_num\n",
    "\n",
    "song_num_dict, song_num_max = make_song_num_dict(train_data_sample2)\n",
    "tag_weights = {tag: np.log(song_num_max / cnt + 1) for tag, cnt in song_num_dict.items()}\n",
    "print(tag_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869ea5c",
   "metadata": {},
   "source": [
    "## 코사인 유사도 사용\n",
    "\n",
    "- 세부 장르를 사용해 코사인 유사도 측정한다\n",
    "- 그후 유사도를 행렬로 저장한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b998e83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "song_tag_appended['gnr_literal'] = song_tag_appended['gnr'].apply(lambda x : (' ').join(x))\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "gnr_mat = count_vect.fit_transform(song_tag_appended['gnr_literal'])\n",
    "\n",
    "gnr_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60269f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "gnr_sim = cosine_similarity(gnr_mat, gnr_mat)\n",
    "gnr_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c46fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_sample = train_data[500:1000].copy()\n",
    "#test_data_sample = train_data_eng.copy()\n",
    "test_data_sample = test_data_sample.reset_index(drop=True)\n",
    "test_my_tags = test_data_sample['tags'].tolist()\n",
    "test_my_songs = test_data_sample['song_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommend import *\n",
    "\n",
    "weight_mat_cv = apply_genre_weight(get_embedding(song_tag_appended, 'cv'))\n",
    "weight_mat_tf = apply_genre_weight(get_embedding(song_tag_appended, 'tf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c30069",
   "metadata": {},
   "source": [
    "# 멀티프로세싱을 이용한 학습 및 결과 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e839267f",
   "metadata": {},
   "source": [
    "## (1) Rec1 & 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [\n",
    "    #태그 / 장르 / 좋아요 / mode(cv/tf)\n",
    "    (False, False, False, 'cv'),\n",
    "    (True, False, False, 'cv'),\n",
    "    (False, True, False, 'cv'),\n",
    "    (True, True, False, 'cv'),\n",
    "    (False, False, True, 'cv'),\n",
    "    (True, False, True, 'cv'),\n",
    "    (False, True, True, 'cv'),\n",
    "    (True, True, True, 'cv'),\n",
    "    #(False, False, False, 'tf'),\n",
    "    #(True, False, False, 'tf'),\n",
    "    #(False, True, False, 'tf'),\n",
    "    #(True, True, False, 'tf'),\n",
    "    #(False, False, True, 'tf'),\n",
    "    #(True, False, True, 'tf'),\n",
    "    #(False, True, True, 'tf'),\n",
    "    #(True, True, True, 'tf')\n",
    "]\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    results = pool.starmap(process_fuc_cos, [(test_my_songs, test_my_tags, song_tag_appended, param[0], param[1], param[2], \n",
    "                                         param[3], w2v, weight_mat_cv, weight_mat_tf, tag_weights) for param in params_list])\n",
    "    \n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3636a92",
   "metadata": {},
   "source": [
    "## (2) Rec1 & 피어슨 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979fef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [\n",
    "    #태그 / 장르 / 좋아요 / mode(cv/tf)\n",
    "    (False, False, False, 'cv'),\n",
    "    (True, False, False, 'cv'),\n",
    "    (False, True, False, 'cv'),\n",
    "    (True, True, False, 'cv'),\n",
    "    (False, False, True, 'cv'),\n",
    "    (True, False, True, 'cv'),\n",
    "    (False, True, True, 'cv'),\n",
    "    (True, True, True, 'cv'),\n",
    "    #(False, False, False, 'tf'),\n",
    "    #(True, False, False, 'tf'),\n",
    "    #(False, True, False, 'tf'),\n",
    "    #(True, True, False, 'tf'),\n",
    "    #(False, False, True, 'tf'),\n",
    "    #(True, False, True, 'tf'),\n",
    "    #(False, True, True, 'tf'),\n",
    "    #(True, True, True, 'tf')\n",
    "]\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    results = pool.starmap(process_fuc_pea, [(test_my_songs, test_my_tags, song_tag_appended, param[0], param[1], param[2], \n",
    "                                         param[3], w2v, weight_mat_cv, weight_mat_tf, tag_weights) for param in params_list])\n",
    "    \n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3222383",
   "metadata": {},
   "source": [
    "## (3) Rec2 & 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030c257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [\n",
    "    #태그 / 장르 / 좋아요 / mode(cv/tf)\n",
    "    (False, False, False, 'cv'),\n",
    "    (True, False, False, 'cv'),\n",
    "    (False, True, False, 'cv'),\n",
    "    (True, True, False, 'cv'),\n",
    "    (False, False, True, 'cv'),\n",
    "    (True, False, True, 'cv'),\n",
    "    (False, True, True, 'cv'),\n",
    "    (True, True, True, 'cv'),\n",
    "    #(False, False, False, 'tf'),\n",
    "    #(True, False, False, 'tf'),\n",
    "    #(False, True, False, 'tf'),\n",
    "    #(True, True, False, 'tf'),\n",
    "    #(False, False, True, 'tf'),\n",
    "    #(True, False, True, 'tf'),\n",
    "    #(False, True, True, 'tf'),\n",
    "    #(True, True, True, 'tf')\n",
    "]\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    results = pool.starmap(process_fuc_cos2, [(test_my_songs, test_my_tags, song_tag_appended, param[0], param[1], param[2], \n",
    "                                         param[3], w2v, weight_mat_cv, weight_mat_tf, tag_weights) for param in params_list])\n",
    "    \n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ca944",
   "metadata": {},
   "source": [
    "## (4) Rec2 & 피어슨 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912af884",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = [\n",
    "    #태그 / 장르 / 좋아요 / mode(cv/tf)\n",
    "    (False, False, False, 'cv'),\n",
    "    (True, False, False, 'cv'),\n",
    "    (False, True, False, 'cv'),\n",
    "    (True, True, False, 'cv'),\n",
    "    (False, False, True, 'cv'),\n",
    "    (True, False, True, 'cv'),\n",
    "    (False, True, True, 'cv'),\n",
    "    (True, True, True, 'cv'),\n",
    "    #(False, False, False, 'tf'),\n",
    "    #(True, False, False, 'tf'),\n",
    "    #(False, True, False, 'tf'),\n",
    "    #(True, True, False, 'tf'),\n",
    "    #(False, False, True, 'tf'),\n",
    "    #(True, False, True, 'tf'),\n",
    "    #(False, True, True, 'tf'),\n",
    "    #(True, True, True, 'tf')\n",
    "]\n",
    "\n",
    "with multiprocessing.Pool(processes=4) as pool:\n",
    "    results = pool.starmap(process_fuc_pea2, [(test_my_songs, test_my_tags, song_tag_appended, param[0], param[1], param[2], \n",
    "                                         param[3], w2v, weight_mat_cv, weight_mat_tf, tag_weights) for param in params_list])\n",
    "    \n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f11596",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec1 = song_recommend(test_my_tags[0], test_my_songs[0], song_tag_appended, 'cos', False, False, False, 'cv')\n",
    "\n",
    "pred_list = rec1['song_id'].tolist()\n",
    "precision_k = get_precision_k(test_my_songs[0], pred_list)\n",
    "recall_k = get_recall_k(test_my_songs[0], pred_list)\n",
    "ndcg = get_ndcg(test_my_songs[0], pred_list, 10)\n",
    "\n",
    "print(\"Recall@K (K=10): {:.2f}\".format(recall_k))\n",
    "print(\"Precision@K (K=10): {:.2f}\".format(precision_k))\n",
    "print(\"nDCG: {:.2f}\".format(ndcg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[Tensorflow2.x]",
   "language": "python",
   "name": "week14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
